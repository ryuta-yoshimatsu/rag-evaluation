{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566c1b35-de9c-4093-9cda-41f1d024aaf2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatabricks-feature-engineering 0.2.0 requires pyspark<4,>=3.1.2, which is not installed.\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84286d94-5d05-4a87-a04c-9e0ad459e91f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Evaluation of Retrieval System with MLflow\n",
    "The question: \"How well does the retriever work with a given query?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9691dc6d-fbf1-447f-a07f-064e01fa778d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Creating Ground Truth dataset\n",
    "\n",
    "The question column contains all the questions that will be evaluated and the source column is the expected source for the answer for the questions as an ordered list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a97f0642-743d-41f8-aacd-3e5912ceedb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import chromadb\n",
    "from typing import List\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.llms import Databricks\n",
    "from langchain.embeddings.databricks import DatabricksEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from chromadb.errors import InvalidDimensionException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8921a00-cf33-4211-a3ce-ce92e0f2b6ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"question\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "        \"source\": [\n",
    "            [\"https://mlflow.org/docs/latest/index.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/tracking/autolog.html\"],\n",
    "        ],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e010f5af-98eb-400a-8380-811f4f0c896c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ]
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ]
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ]
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2105f35-077f-428c-b1e6-8fe1b9f23707",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Evaluate the Embedding Model with MLflow\n",
    "\n",
    "There are three built-in metrics mlflow.metrics.precision_at_k(k),  mlflow.metrics.recall_at_k(k) and mlflow.metrics.ndcg_at_k(k) to help determine how effective your retriever is at predicting the most relevant results for you. For example, suppose the vector database returns 10 results (k=10), and out of these 10 results, 4 are relevant to your query. The precision_at_10 would be 4/10 or 40%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a17e7dde-7d5f-4821-b739-616b53c79791",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    [ \n",
    "     \"https://mlflow.org/docs/latest/index.html\",\n",
    "     \"https://mlflow.org/docs/latest/tracking/autolog.html\", \n",
    "     \"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\",\n",
    "     \"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\",\n",
    "     \"https://mlflow.org/docs/latest/model-evaluation/index.html\",\n",
    "     \"https://mlflow.org/docs/latest/models.html\",\n",
    "     \"https://mlflow.org/docs/latest/deep-learning/index.html\"])\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f884f3e7-1d25-4498-a084-06fbf0afa97a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/15 09:41:53 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/03/15 09:41:53 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/03/15 09:41:54 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/03/15 09:41:54 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n2024/03/15 09:41:54 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n2024/03/15 09:41:54 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ndcg_at_3\n2024/03/15 09:42:10 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/03/15 09:42:10 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/03/15 09:42:11 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/03/15 09:42:11 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n2024/03/15 09:42:11 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n2024/03/15 09:42:11 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ndcg_at_3\n2024/03/15 09:42:22 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/03/15 09:42:22 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/03/15 09:42:22 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/03/15 09:42:22 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n2024/03/15 09:42:22 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n2024/03/15 09:42:22 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ndcg_at_3\n2024/03/15 09:42:41 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/03/15 09:42:41 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/03/15 09:42:42 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/03/15 09:42:42 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n2024/03/15 09:42:42 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n2024/03/15 09:42:42 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ndcg_at_3\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b302728dc94baf8d9ffb30c36ab76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c97702e7d34edeaa5ff003ec6633b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e3ca5d288449beaa60c97f13c0a02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e2210a0a9a4ec88a570e21f8be3463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>outputs</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/deep-learning/index.html, https://mlflow.org/docs/latest/deep-learning/index.html)</td><td>0.6666666667000001</td><td>1</td><td>1.0</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.33333333330000003</td><td>1</td><td>0.6934264036000001</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/deep-learning/index.html",
          "https://mlflow.org/docs/latest/deep-learning/index.html"
         ],
         0.6666666667000001,
         1,
         1.0
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         1.0,
         1,
         1.0
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.33333333330000003,
         1,
         0.6934264036000001
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1.0,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>outputs</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/deep-learning/index.html)</td><td>0.6666666667000001</td><td>1</td><td>0.9197207891</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>0.6666666667000001</td><td>1</td><td>1.0</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/models.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.0</td><td>0</td><td>0.30657359640000004</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/deep-learning/index.html"
         ],
         0.6666666667000001,
         1,
         0.9197207891
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         0.6666666667000001,
         1,
         1.0
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/models.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.0,
         0,
         0.30657359640000004
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1.0,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>outputs</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/deep-learning/index.html, https://mlflow.org/docs/latest/index.html)</td><td>0.33333333330000003</td><td>1</td><td>1.0</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>0.6666666667000001</td><td>1</td><td>0.9197207891</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.6666666667000001</td><td>1</td><td>0.6934264036000001</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/deep-learning/index.html",
          "https://mlflow.org/docs/latest/index.html"
         ],
         0.33333333330000003,
         1,
         1.0
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         0.6666666667000001,
         1,
         0.9197207891
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.6666666667000001,
         1,
         0.6934264036000001
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1.0,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>outputs</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/deep-learning/index.html, https://mlflow.org/docs/latest/index.html)</td><td>0.33333333330000003</td><td>1</td><td>1.0</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>0.6666666667000001</td><td>1</td><td>0.9197207891</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.6666666667000001</td><td>1</td><td>0.6934264036000001</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/deep-learning/index.html",
          "https://mlflow.org/docs/latest/index.html"
         ],
         0.33333333330000003,
         1,
         1.0
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         0.6666666667000001,
         1,
         0.9197207891
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.6666666667000001,
         1,
         0.6934264036000001
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1.0,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_embedding(embedding_function):\n",
    "    CHUNK_SIZE = 1000\n",
    "    list_of_documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=0, separator=\"\\n\")\n",
    "    docs = text_splitter.split_documents(list_of_documents)\n",
    "    try:\n",
    "        retriever = Chroma.from_documents(docs, embedding_function).as_retriever()\n",
    "    except InvalidDimensionException:\n",
    "        Chroma().delete_collection()\n",
    "        retriever = Chroma.from_documents(docs, embedding_function).as_retriever()\n",
    "\n",
    "    def retrieve_doc_ids(question: str) -> List[str]:\n",
    "        docs = retriever.get_relevant_documents(question)\n",
    "        doc_ids = [doc.metadata[\"source\"] for doc in docs]\n",
    "        return doc_ids\n",
    "\n",
    "    def retriever_model_function(question_df: pd.DataFrame) -> pd.Series:\n",
    "        return question_df[\"question\"].apply(retrieve_doc_ids)\n",
    "\n",
    "    # Evaluating a function\n",
    "    with mlflow.start_run() as run:\n",
    "        evaluate_results = mlflow.evaluate(\n",
    "                model=retriever_model_function,\n",
    "                data=eval_data,\n",
    "                model_type=\"retriever\",\n",
    "                targets=\"source\",\n",
    "                evaluators=\"default\",\n",
    "            )\n",
    "    return evaluate_results\n",
    "\n",
    "# Make sure you have access to Foundation Model API pay per token\n",
    "result1 = evaluate_embedding(DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\")) \n",
    "\n",
    "# Make sure you have adeployed bge_base_en_v1_5 and bge_small_en_v1_5 behind model serving endpoint\n",
    "result2 = evaluate_embedding(DatabricksEmbeddings(endpoint=\"bge_base_en_v1_5\"))\n",
    "result3 = evaluate_embedding(DatabricksEmbeddings(endpoint=\"bge_small_en_v1_5\"))\n",
    "\n",
    "# Make sure you extrenal model endpoint cread in model serving\n",
    "result4 = evaluate_embedding(DatabricksEmbeddings(endpoint=\"timo_lackmann_oai_embedding\"))\n",
    "\n",
    "eval_results_of_retriever_df_bge_large = result1.tables[\"eval_results_table\"]\n",
    "eval_results_of_retriever_df_bge_base = result2.tables[\"eval_results_table\"]\n",
    "eval_results_of_retriever_df_bge_small = result3.tables[\"eval_results_table\"]\n",
    "eval_results_of_retriever_df_openai_ada = result3.tables[\"eval_results_table\"]\n",
    "\n",
    "display(eval_results_of_retriever_df_bge_large)\n",
    "display(eval_results_of_retriever_df_bge_base)\n",
    "display(eval_results_of_retriever_df_bge_small)\n",
    "display(eval_results_of_retriever_df_openai_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a0e3b04-061f-483e-911b-7d4798fd4c19",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Evaluate retriever with different Top K values with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "778ae14a-2527-4431-8f36-4f15393a1c59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/mlflow/data/pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  return _infer_schema(self._df)\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: precision_at_1\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: precision_at_2\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: precision_at_3\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: recall_at_1\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: recall_at_2\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: recall_at_3\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: ndcg_at_1\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: ndcg_at_2\n2024/03/15 09:42:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: ndcg_at_3\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01be6f57d6ba4c30904b53bd29bfbe6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th><th>source</th><th>outputs</th><th>precision_at_1/score</th><th>precision_at_2/score</th><th>recall_at_1/score</th><th>recall_at_2/score</th><th>ndcg_at_1/score</th><th>ndcg_at_2/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>0.6666666667000001</td><td>1</td><td>1.0</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/deep-learning/index.html, https://mlflow.org/docs/latest/deep-learning/index.html)</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1.0</td></tr><tr><td>What is Databricks?</td><td>1.0</td><td>1</td><td>1.0</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1.0</td></tr><tr><td>How to serve a model on Databricks?</td><td>0.33333333330000003</td><td>1</td><td>0.6934264036000001</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.38685280720000004</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>1.0</td><td>1</td><td>1.0</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         0.6666666667000001,
         1,
         1.0,
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/deep-learning/index.html",
          "https://mlflow.org/docs/latest/deep-learning/index.html"
         ],
         1,
         1,
         1,
         1,
         1,
         1.0
        ],
        [
         "What is Databricks?",
         1.0,
         1,
         1.0,
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         1,
         1,
         1,
         1,
         1,
         1.0
        ],
        [
         "How to serve a model on Databricks?",
         0.33333333330000003,
         1,
         0.6934264036000001,
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0,
         0,
         0,
         0,
         0,
         0.38685280720000004
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         1.0,
         1,
         1.0,
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1,
         1,
         1,
         1,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_1/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "precision_at_2/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_1/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_2/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_1/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_2/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating a static evaluation dataset\n",
    "with mlflow.start_run() as run:\n",
    "    evaluate_results = mlflow.evaluate(\n",
    "    data=eval_results_of_retriever_df_bge1,\n",
    "    targets=\"source\",\n",
    "    predictions=\"outputs\",\n",
    "    evaluators=\"default\",\n",
    "    extra_metrics=[\n",
    "        mlflow.metrics.precision_at_k(1),\n",
    "        mlflow.metrics.precision_at_k(2),\n",
    "        mlflow.metrics.precision_at_k(3),\n",
    "        mlflow.metrics.recall_at_k(1),\n",
    "        mlflow.metrics.recall_at_k(2),\n",
    "        mlflow.metrics.recall_at_k(3),\n",
    "        mlflow.metrics.ndcg_at_k(1),\n",
    "        mlflow.metrics.ndcg_at_k(2),\n",
    "        mlflow.metrics.ndcg_at_k(3),\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(evaluate_results.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "257633cc-0988-44f7-91ea-eefe1cf92ae1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Evaluate the Chunking Strategy with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ce8095a-a494-44ba-aa10-8308e757f5e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/15 09:43:26 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/03/15 09:43:26 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/03/15 09:43:27 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/03/15 09:43:27 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n2024/03/15 09:43:27 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n2024/03/15 09:43:27 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ndcg_at_3\n2024/03/15 09:43:38 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/03/15 09:43:38 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/03/15 09:43:39 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/03/15 09:43:39 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n2024/03/15 09:43:39 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n2024/03/15 09:43:39 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ndcg_at_3\n2024/03/15 09:43:48 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/03/15 09:43:48 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/03/15 09:43:49 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/03/15 09:43:49 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n2024/03/15 09:43:49 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n2024/03/15 09:43:49 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ndcg_at_3\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c749dd44bae4ecb826fa7514183a049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>outputs</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html)</td><td>1.0</td><td>1</td><td>1</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.6666666667000001</td><td>1</td><td>1</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>1.0</td><td>1</td><td>1</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1.0</td><td>1</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html"
         ],
         1.0,
         1,
         1
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.6666666667000001,
         1,
         1
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         1.0,
         1,
         1
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1.0,
         1,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581244fbab7543b5abfbd7b385da8486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>outputs</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/models.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.33333333330000003</td><td>1</td><td>0.6309297536</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html"
         ],
         1.0,
         1,
         1.0
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         1.0,
         1,
         1.0
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/models.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.33333333330000003,
         1,
         0.6309297536
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1.0,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af7a737e7de43f69f1a02caa63917ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>outputs</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html, https://mlflow.org/docs/latest/index.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/models.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.33333333330000003</td><td>1</td><td>0.6309297536</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html",
          "https://mlflow.org/docs/latest/index.html"
         ],
         1.0,
         1,
         1.0
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         1.0,
         1,
         1.0
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/models.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.33333333330000003,
         1,
         0.6309297536
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1.0,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_chunk_size(chunk_size):\n",
    "  list_of_documents = loader.load()\n",
    "  text_splitter = CharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=0,separator=\"\\n\")\n",
    "  docs = text_splitter.split_documents(list_of_documents)\n",
    "  embedding_function = DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\")\n",
    "  \n",
    "  try:\n",
    "      retriever = Chroma.from_documents(docs, embedding_function).as_retriever()\n",
    "  except InvalidDimensionException:\n",
    "      Chroma().delete_collection()\n",
    "      retriever = Chroma.from_documents(docs, embedding_function).as_retriever()\n",
    "  \n",
    "  def retrieve_doc_ids(question: str) -> List[str]:\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    doc_ids = [doc.metadata[\"source\"] for doc in docs]\n",
    "    return doc_ids\n",
    "   \n",
    "  def retriever_model_function(question_df: pd.DataFrame) -> pd.Series:\n",
    "    return question_df[\"question\"].apply(retrieve_doc_ids)\n",
    "\n",
    "  with mlflow.start_run() as run:\n",
    "      evaluate_results = mlflow.evaluate(\n",
    "          model=retriever_model_function,\n",
    "          data=eval_data,\n",
    "          model_type=\"retriever\",\n",
    "          targets=\"source\",\n",
    "          evaluators=\"default\",\n",
    "      )\n",
    "  return evaluate_results\n",
    "\n",
    "result1 = evaluate_chunk_size(500)\n",
    "result2 = evaluate_chunk_size(1000)\n",
    "result3 = evaluate_chunk_size(2000)\n",
    "\n",
    "display(result1.tables[\"eval_results_table\"])\n",
    "display(result2.tables[\"eval_results_table\"])\n",
    "display(result3.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1766ce77-41ce-43f5-8faa-e107e3d8eb10",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Evaluation of GenAI results with MLflow\n",
    "The question: \"How good is the response of the GenAI app with a given prompt and context?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4cb6b72-521f-4fbb-a6ef-66c8abd7a66a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Create a GenAI app with LangChain using docs from the MLflow website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c093cdb2-e355-45ea-bade-35a875299d27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatDatabricks\n",
    "from mlflow.deployments import set_deployments_target\n",
    "from  mlflow.metrics.genai.metric_definitions import relevance\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    [ \n",
    "     \"https://mlflow.org/docs/latest/index.html\",\n",
    "     \"https://mlflow.org/docs/latest/tracking/autolog.html\", \n",
    "     \"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\",\n",
    "     \"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\",\n",
    "     \"https://mlflow.org/docs/latest/model-evaluation/index.html\",\n",
    "     \"https://mlflow.org/docs/latest/models.html\",\n",
    "     \"https://mlflow.org/docs/latest/deep-learning/index.html\"])\n",
    "\n",
    "documents = loader.load()\n",
    "CHUNK_SIZE = 1000\n",
    "text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=0, separator=\"\\n\")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "def evaluate_model(model_name, eval_df):\n",
    "\n",
    "    llm = ChatDatabricks(endpoint=model_name, max_tokens=500)\n",
    "\n",
    "    # create the embedding function using Databricks Foundation Model APIs\n",
    "    embedding_function = DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\")\n",
    "    retriever = Chroma.from_documents(texts, embedding_function).as_retriever(fetch_k=3)\n",
    "\n",
    "    def model(input_df):\n",
    "        return input_df[\"questions\"].map(qa).tolist()\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "    set_deployments_target(\"databricks\") # To retrieve all endpoint in your Databricks Workspace\n",
    "\n",
    "    #You can also use any model you have hosted on Databricks, models from the Marketplace or models in the Foundation model API\n",
    "    relevance_metric = relevance(model=f\"endpoints:/databricks-mixtral-8x7b-instruct\") \n",
    "\n",
    "    with mlflow.start_run():\n",
    "        results =  mlflow.evaluate(\n",
    "            model,\n",
    "            eval_df,\n",
    "            model_type=\"question-answering\",\n",
    "            evaluators=\"default\",\n",
    "            predictions=\"result\",\n",
    "            extra_metrics=[relevance_metric, mlflow.metrics.latency()],\n",
    "            evaluator_config={\n",
    "                \"col_mapping\": {\n",
    "                    \"inputs\": \"questions\",\n",
    "                    \"context\": \"source_documents\",\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e64effc-26d8-496c-994a-63f5def851d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/15 12:11:47 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/03/15 12:11:47 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/03/15 12:12:02 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/03/15 12:12:02 WARNING mlflow.metrics.metric_definitions: Failed to load flesch kincaid metric, skipping metric logging.\n2024/03/15 12:12:02 WARNING mlflow.metrics.metric_definitions: Failed to load automated readability index metric, skipping metric logging.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e919b93a58e4d48bdb566492ba7cac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/15 12:12:04 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: token_count\n2024/03/15 12:12:04 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: toxicity\n2024/03/15 12:12:06 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: flesch_kincaid_grade_level\n2024/03/15 12:12:06 WARNING mlflow.metrics.metric_definitions: Failed to load flesch kincaid metric, skipping metric logging.\n2024/03/15 12:12:06 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ari_grade_level\n2024/03/15 12:12:06 WARNING mlflow.metrics.metric_definitions: Failed to load automated readability index metric, skipping metric logging.\n2024/03/15 12:12:06 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: exact_match\n2024/03/15 12:12:06 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: relevance\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cfc27655d54385b0c8acf7fe69465d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/15 12:12:18 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/03/15 12:12:18 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/03/15 12:12:36 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/03/15 12:12:36 WARNING mlflow.metrics.metric_definitions: Failed to load flesch kincaid metric, skipping metric logging.\n2024/03/15 12:12:36 WARNING mlflow.metrics.metric_definitions: Failed to load automated readability index metric, skipping metric logging.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c332d89108314486866941cda42b1e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/15 12:12:38 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: token_count\n2024/03/15 12:12:38 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: toxicity\n2024/03/15 12:12:41 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: flesch_kincaid_grade_level\n2024/03/15 12:12:41 WARNING mlflow.metrics.metric_definitions: Failed to load flesch kincaid metric, skipping metric logging.\n2024/03/15 12:12:41 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ari_grade_level\n2024/03/15 12:12:41 WARNING mlflow.metrics.metric_definitions: Failed to load automated readability index metric, skipping metric logging.\n2024/03/15 12:12:41 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: exact_match\n2024/03/15 12:12:41 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: relevance\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215371742968402ca42be7d79729e0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"questions\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "result_llama = evaluate_model(\"databricks-llama-2-70b-chat\", eval_df)\n",
    "result_mixtral = evaluate_model(\"databricks-mixtral-8x7b-instruct\", eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef3cc891-f42c-4730-9f6d-4d0a9a4804eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4f35def6914d8996d0c8a96f08f79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>questions</th><th>outputs</th><th>source_documents</th><th>latency</th><th>token_count</th><th>toxicity/v1/score</th><th>relevance/v1/score</th><th>relevance/v1/justification</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>MLflow is an open-source platform designed to assist machine learning practitioners and teams in handling the complexities of the machine learning process. It focuses on the full lifecycle of machine learning projects, ensuring that each phase is manageable, traceable, and reproducible.</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/index.html, MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation), MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n",
       "2.11.1\n",
       " MLflow\n",
       "What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "R API\n",
       "Java API\n",
       "REST API\n",
       "Official MLflow Docker Image\n",
       "Community Model Flavors\n",
       "Tutorials and Examples\n",
       "Contribute\n",
       "Documentation \n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle\n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle \n",
       "MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\n",
       "handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\n",
       "machine learning projects, ensuring that each phase is manageable, traceable, and reproducible., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/index.html, MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation), MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n",
       "2.11.1\n",
       " MLflow\n",
       "What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "R API\n",
       "Java API\n",
       "REST API\n",
       "Official MLflow Docker Image\n",
       "Community Model Flavors\n",
       "Tutorials and Examples\n",
       "Contribute\n",
       "Documentation \n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle\n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle \n",
       "MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\n",
       "handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\n",
       "machine learning projects, ensuring that each phase is manageable, traceable, and reproducible., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/index.html, MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation), MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n",
       "2.11.1\n",
       " MLflow\n",
       "What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "R API\n",
       "Java API\n",
       "REST API\n",
       "Official MLflow Docker Image\n",
       "Community Model Flavors\n",
       "Tutorials and Examples\n",
       "Contribute\n",
       "Documentation \n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle\n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle \n",
       "MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\n",
       "handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\n",
       "machine learning projects, ensuring that each phase is manageable, traceable, and reproducible., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/index.html, MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation), MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n",
       "2.11.1\n",
       " MLflow\n",
       "What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "R API\n",
       "Java API\n",
       "REST API\n",
       "Official MLflow Docker Image\n",
       "Community Model Flavors\n",
       "Tutorials and Examples\n",
       "Contribute\n",
       "Documentation \n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle\n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle \n",
       "MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\n",
       "handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\n",
       "machine learning projects, ensuring that each phase is manageable, traceable, and reproducible., Document))</td><td>2.3419442177</td><td>50</td><td>1.3705530000000002E-4</td><td>5</td><td>The output fully and accurately answers the question, providing a comprehensive explanation of MLflow using the provided context. It directly addresses the question and is consistent with the context, offering a detailed response that covers the main features and purpose of MLflow.</td></tr><tr><td>What is Databricks?</td><td>Databricks is a cloud-based big data platform that offers a free, limited-use version called Databricks Community Edition (CE). Databricks CE allows users to access a micro-cluster, cluster manager, and notebook environment, and also provides the ability to store and view MLflow experiments without being charged.</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks Community Edition (CE) is the free, limited-use version of the\n",
       "cloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\n",
       "a cluster manager and notebook environment. All users can share their notebooks and host them free of\n",
       "charge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\n",
       "being charged.\n",
       "To use Databricks CE to store and view our MLflow experiments, basically we need to:\n",
       "Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "Install Dependencies, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks Community Edition (CE) is the free, limited-use version of the\n",
       "cloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\n",
       "a cluster manager and notebook environment. All users can share their notebooks and host them free of\n",
       "charge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\n",
       "being charged.\n",
       "To use Databricks CE to store and view our MLflow experiments, basically we need to:\n",
       "Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "Install Dependencies, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks Community Edition (CE) is the free, limited-use version of the\n",
       "cloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\n",
       "a cluster manager and notebook environment. All users can share their notebooks and host them free of\n",
       "charge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\n",
       "being charged.\n",
       "To use Databricks CE to store and view our MLflow experiments, basically we need to:\n",
       "Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "Install Dependencies, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks Community Edition (CE) is the free, limited-use version of the\n",
       "cloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\n",
       "a cluster manager and notebook environment. All users can share their notebooks and host them free of\n",
       "charge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\n",
       "being charged.\n",
       "To use Databricks CE to store and view our MLflow experiments, basically we need to:\n",
       "Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "Install Dependencies, Document))</td><td>2.3812563419</td><td>62</td><td>1.498092E-4</td><td>5</td><td>The output directly answers the question about what Databricks is, providing comprehensive information about Databricks CE, its features, and how it can be used to store and view MLflow experiments without charge. The provided context is used effectively to fully address the input.</td></tr><tr><td>How to serve a model on Databricks?</td><td>Serving a model on Databricks can be done by following these steps:\n",
       "\n",
       "1. Log your model into the Databricks MLflow server.\n",
       "2. Register your model.\n",
       "3. Serve your model by a few clicks.\n",
       "\n",
       "Note that the serving feature is only available on production Databricks workspace and not on Databricks CE. To use the production workspace, you need to change the host to be the production workspace, for example, <https://dbc-1234567-123.cloud.databricks.com>.\n",
       "\n",
       "For more information on how Databricks power your Machine Learning workflow, please refer to the documentation here.</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\n",
       "MLflow server, and you can register your model then serve your model by a few clicks. Serving feature\n",
       "is only available on production Databricks workspace, and not available on Databricks CE.\n",
       "The method of using production Databricks is the same as using Databricks CE, you only need to\n",
       "change the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\n",
       "For more information about how Databricks power your Machine Learning workflow, please refer to the doc\n",
       "here.\n",
       "To use AzureML as the tracking server, please read\n",
       "the doc here\n",
       "Conclusion \n",
       "That’s all about how to use a production platform as the tracking server. Please see the pros and cons\n",
       "of this method below:\n",
       "Pros\n",
       "Effortless setup.\n",
       "Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\n",
       "MLflow server, and you can register your model then serve your model by a few clicks. Serving feature\n",
       "is only available on production Databricks workspace, and not available on Databricks CE.\n",
       "The method of using production Databricks is the same as using Databricks CE, you only need to\n",
       "change the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\n",
       "For more information about how Databricks power your Machine Learning workflow, please refer to the doc\n",
       "here.\n",
       "To use AzureML as the tracking server, please read\n",
       "the doc here\n",
       "Conclusion \n",
       "That’s all about how to use a production platform as the tracking server. Please see the pros and cons\n",
       "of this method below:\n",
       "Pros\n",
       "Effortless setup.\n",
       "Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\n",
       "MLflow server, and you can register your model then serve your model by a few clicks. Serving feature\n",
       "is only available on production Databricks workspace, and not available on Databricks CE.\n",
       "The method of using production Databricks is the same as using Databricks CE, you only need to\n",
       "change the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\n",
       "For more information about how Databricks power your Machine Learning workflow, please refer to the doc\n",
       "here.\n",
       "To use AzureML as the tracking server, please read\n",
       "the doc here\n",
       "Conclusion \n",
       "That’s all about how to use a production platform as the tracking server. Please see the pros and cons\n",
       "of this method below:\n",
       "Pros\n",
       "Effortless setup.\n",
       "Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\n",
       "MLflow server, and you can register your model then serve your model by a few clicks. Serving feature\n",
       "is only available on production Databricks workspace, and not available on Databricks CE.\n",
       "The method of using production Databricks is the same as using Databricks CE, you only need to\n",
       "change the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\n",
       "For more information about how Databricks power your Machine Learning workflow, please refer to the doc\n",
       "here.\n",
       "To use AzureML as the tracking server, please read\n",
       "the doc here\n",
       "Conclusion \n",
       "That’s all about how to use a production platform as the tracking server. Please see the pros and cons\n",
       "of this method below:\n",
       "Pros\n",
       "Effortless setup.\n",
       "Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily., Document))</td><td>4.6634559631</td><td>125</td><td>6.524473E-4</td><td>5</td><td>The output directly answers the question about serving a model on Databricks by providing a clear, step-by-step process. It is consistent with the provided context, including the necessity of using a production workspace and changing the host. The output is comprehensive and thoroughly addresses the input.</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>You can enable MLflow Autologging for your workspace by default by adding the following line of code to your `~/.bashrc` or `~/.bash_profile` file:\n",
       "```\n",
       "mlflow autolog\n",
       "```\n",
       "This will enable autologging for all supported libraries as soon as you import them in your Python code.\n",
       "\n",
       "Alternatively, you can also enable autologging for specific libraries by adding the following lines of code to your `~/.bashrc` or `~/.bash_profile` file:\n",
       "```\n",
       "mlflow pytorch autolog\n",
       "mlflow sklearn autolog(disable=True)\n",
       "```\n",
       "This will enable autologging only for PyTorch and disable it for scikit-learn.\n",
       "\n",
       "Note that the `~/.bashrc` or `~/.bash_profile` file is a configuration file that is executed when you start a new shell session. By adding the above lines of code to this file, you can enable autologging for your workspace by default.</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation), extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow\n",
       "# Option 1: Enable autologging only for PyTorch\n",
       "mlflow.pytorch.autolog()\n",
       "# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\n",
       "mlflow.sklearn.autolog(disable=True)\n",
       "mlflow.autolog()\n",
       "Supported Libraries \n",
       "Note\n",
       "The generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation), extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow\n",
       "# Option 1: Enable autologging only for PyTorch\n",
       "mlflow.pytorch.autolog()\n",
       "# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\n",
       "mlflow.sklearn.autolog(disable=True)\n",
       "mlflow.autolog()\n",
       "Supported Libraries \n",
       "Note\n",
       "The generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation), extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow\n",
       "# Option 1: Enable autologging only for PyTorch\n",
       "mlflow.pytorch.autolog()\n",
       "# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\n",
       "mlflow.sklearn.autolog(disable=True)\n",
       "mlflow.autolog()\n",
       "Supported Libraries \n",
       "Note\n",
       "The generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation), extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow\n",
       "# Option 1: Enable autologging only for PyTorch\n",
       "mlflow.pytorch.autolog()\n",
       "# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\n",
       "mlflow.sklearn.autolog(disable=True)\n",
       "mlflow.autolog()\n",
       "Supported Libraries \n",
       "Note\n",
       "The generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it., Document))</td><td>5.3800733089</td><td>198</td><td>0.0019109796000000001</td><td>5</td><td>The output directly answers the question about enabling MLflow Autologging for a workspace by default, providing clear instructions and examples. It is fully consistent with the provided context and additional information.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         "MLflow is an open-source platform designed to assist machine learning practitioners and teams in handling the complexities of the machine learning process. It focuses on the full lifecycle of machine learning projects, ensuring that each phase is manageable, traceable, and reproducible.",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/index.html",
            "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation"
           ],
           "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n2.11.1\n MLflow\nWhat is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nR API\nJava API\nREST API\nOfficial MLflow Docker Image\nCommunity Model Flavors\nTutorials and Examples\nContribute\nDocumentation \nMLflow: A Tool for Managing the Machine Learning Lifecycle\nMLflow: A Tool for Managing the Machine Learning Lifecycle \nMLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\nhandling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\nmachine learning projects, ensuring that each phase is manageable, traceable, and reproducible.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/index.html",
            "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation"
           ],
           "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n2.11.1\n MLflow\nWhat is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nR API\nJava API\nREST API\nOfficial MLflow Docker Image\nCommunity Model Flavors\nTutorials and Examples\nContribute\nDocumentation \nMLflow: A Tool for Managing the Machine Learning Lifecycle\nMLflow: A Tool for Managing the Machine Learning Lifecycle \nMLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\nhandling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\nmachine learning projects, ensuring that each phase is manageable, traceable, and reproducible.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/index.html",
            "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation"
           ],
           "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n2.11.1\n MLflow\nWhat is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nR API\nJava API\nREST API\nOfficial MLflow Docker Image\nCommunity Model Flavors\nTutorials and Examples\nContribute\nDocumentation \nMLflow: A Tool for Managing the Machine Learning Lifecycle\nMLflow: A Tool for Managing the Machine Learning Lifecycle \nMLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\nhandling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\nmachine learning projects, ensuring that each phase is manageable, traceable, and reproducible.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/index.html",
            "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation"
           ],
           "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n2.11.1\n MLflow\nWhat is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nR API\nJava API\nREST API\nOfficial MLflow Docker Image\nCommunity Model Flavors\nTutorials and Examples\nContribute\nDocumentation \nMLflow: A Tool for Managing the Machine Learning Lifecycle\nMLflow: A Tool for Managing the Machine Learning Lifecycle \nMLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\nhandling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\nmachine learning projects, ensuring that each phase is manageable, traceable, and reproducible.",
           "Document"
          ]
         ],
         2.3419442177,
         50,
         1.3705530000000002E-4,
         5,
         "The output fully and accurately answers the question, providing a comprehensive explanation of MLflow using the provided context. It directly addresses the question and is consistent with the context, offering a detailed response that covers the main features and purpose of MLflow."
        ],
        [
         "What is Databricks?",
         "Databricks is a cloud-based big data platform that offers a free, limited-use version called Databricks Community Edition (CE). Databricks CE allows users to access a micro-cluster, cluster manager, and notebook environment, and also provides the ability to store and view MLflow experiments without being charged.",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks Community Edition (CE) is the free, limited-use version of the\ncloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\na cluster manager and notebook environment. All users can share their notebooks and host them free of\ncharge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\nbeing charged.\nTo use Databricks CE to store and view our MLflow experiments, basically we need to:\nCreate a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\nInstall Dependencies",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks Community Edition (CE) is the free, limited-use version of the\ncloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\na cluster manager and notebook environment. All users can share their notebooks and host them free of\ncharge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\nbeing charged.\nTo use Databricks CE to store and view our MLflow experiments, basically we need to:\nCreate a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\nInstall Dependencies",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks Community Edition (CE) is the free, limited-use version of the\ncloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\na cluster manager and notebook environment. All users can share their notebooks and host them free of\ncharge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\nbeing charged.\nTo use Databricks CE to store and view our MLflow experiments, basically we need to:\nCreate a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\nInstall Dependencies",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks Community Edition (CE) is the free, limited-use version of the\ncloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\na cluster manager and notebook environment. All users can share their notebooks and host them free of\ncharge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\nbeing charged.\nTo use Databricks CE to store and view our MLflow experiments, basically we need to:\nCreate a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\nInstall Dependencies",
           "Document"
          ]
         ],
         2.3812563419,
         62,
         1.498092E-4,
         5,
         "The output directly answers the question about what Databricks is, providing comprehensive information about Databricks CE, its features, and how it can be used to store and view MLflow experiments without charge. The provided context is used effectively to fully address the input."
        ],
        [
         "How to serve a model on Databricks?",
         "Serving a model on Databricks can be done by following these steps:\n\n1. Log your model into the Databricks MLflow server.\n2. Register your model.\n3. Serve your model by a few clicks.\n\nNote that the serving feature is only available on production Databricks workspace and not on Databricks CE. To use the production workspace, you need to change the host to be the production workspace, for example, <https://dbc-1234567-123.cloud.databricks.com>.\n\nFor more information on how Databricks power your Machine Learning workflow, please refer to the documentation here.",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\nMLflow server, and you can register your model then serve your model by a few clicks. Serving feature\nis only available on production Databricks workspace, and not available on Databricks CE.\nThe method of using production Databricks is the same as using Databricks CE, you only need to\nchange the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\nFor more information about how Databricks power your Machine Learning workflow, please refer to the doc\nhere.\nTo use AzureML as the tracking server, please read\nthe doc here\nConclusion \nThat’s all about how to use a production platform as the tracking server. Please see the pros and cons\nof this method below:\nPros\nEffortless setup.\nGood for collaboration, e.g., you can share your MLflow experiment with your teammates easily.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\nMLflow server, and you can register your model then serve your model by a few clicks. Serving feature\nis only available on production Databricks workspace, and not available on Databricks CE.\nThe method of using production Databricks is the same as using Databricks CE, you only need to\nchange the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\nFor more information about how Databricks power your Machine Learning workflow, please refer to the doc\nhere.\nTo use AzureML as the tracking server, please read\nthe doc here\nConclusion \nThat’s all about how to use a production platform as the tracking server. Please see the pros and cons\nof this method below:\nPros\nEffortless setup.\nGood for collaboration, e.g., you can share your MLflow experiment with your teammates easily.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\nMLflow server, and you can register your model then serve your model by a few clicks. Serving feature\nis only available on production Databricks workspace, and not available on Databricks CE.\nThe method of using production Databricks is the same as using Databricks CE, you only need to\nchange the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\nFor more information about how Databricks power your Machine Learning workflow, please refer to the doc\nhere.\nTo use AzureML as the tracking server, please read\nthe doc here\nConclusion \nThat’s all about how to use a production platform as the tracking server. Please see the pros and cons\nof this method below:\nPros\nEffortless setup.\nGood for collaboration, e.g., you can share your MLflow experiment with your teammates easily.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\nMLflow server, and you can register your model then serve your model by a few clicks. Serving feature\nis only available on production Databricks workspace, and not available on Databricks CE.\nThe method of using production Databricks is the same as using Databricks CE, you only need to\nchange the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\nFor more information about how Databricks power your Machine Learning workflow, please refer to the doc\nhere.\nTo use AzureML as the tracking server, please read\nthe doc here\nConclusion \nThat’s all about how to use a production platform as the tracking server. Please see the pros and cons\nof this method below:\nPros\nEffortless setup.\nGood for collaboration, e.g., you can share your MLflow experiment with your teammates easily.",
           "Document"
          ]
         ],
         4.6634559631,
         125,
         6.524473E-4,
         5,
         "The output directly answers the question about serving a model on Databricks by providing a clear, step-by-step process. It is consistent with the provided context, including the necessity of using a production workspace and changing the host. The output is comprehensive and thoroughly addresses the input."
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         "You can enable MLflow Autologging for your workspace by default by adding the following line of code to your `~/.bashrc` or `~/.bash_profile` file:\n```\nmlflow autolog\n```\nThis will enable autologging for all supported libraries as soon as you import them in your Python code.\n\nAlternatively, you can also enable autologging for specific libraries by adding the following lines of code to your `~/.bashrc` or `~/.bash_profile` file:\n```\nmlflow pytorch autolog\nmlflow sklearn autolog(disable=True)\n```\nThis will enable autologging only for PyTorch and disable it for scikit-learn.\n\nNote that the `~/.bashrc` or `~/.bash_profile` file is a configuration file that is executed when you start a new shell session. By adding the above lines of code to this file, you can enable autologging for your workspace by default.",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation"
           ],
           "extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\nSee mlflow.autolog() for the full set of arguments you can use.\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow\n# Option 1: Enable autologging only for PyTorch\nmlflow.pytorch.autolog()\n# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\nmlflow.sklearn.autolog(disable=True)\nmlflow.autolog()\nSupported Libraries \nNote\nThe generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation"
           ],
           "extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\nSee mlflow.autolog() for the full set of arguments you can use.\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow\n# Option 1: Enable autologging only for PyTorch\nmlflow.pytorch.autolog()\n# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\nmlflow.sklearn.autolog(disable=True)\nmlflow.autolog()\nSupported Libraries \nNote\nThe generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation"
           ],
           "extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\nSee mlflow.autolog() for the full set of arguments you can use.\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow\n# Option 1: Enable autologging only for PyTorch\nmlflow.pytorch.autolog()\n# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\nmlflow.sklearn.autolog(disable=True)\nmlflow.autolog()\nSupported Libraries \nNote\nThe generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation"
           ],
           "extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\nSee mlflow.autolog() for the full set of arguments you can use.\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow\n# Option 1: Enable autologging only for PyTorch\nmlflow.pytorch.autolog()\n# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\nmlflow.sklearn.autolog(disable=True)\nmlflow.autolog()\nSupported Libraries \nNote\nThe generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it.",
           "Document"
          ]
         ],
         5.3800733089,
         198,
         0.0019109796000000001,
         5,
         "The output directly answers the question about enabling MLflow Autologging for a workspace by default, providing clear instructions and examples. It is fully consistent with the provided context and additional information."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "questions",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source_documents",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"lc_attributes\",\"type\":{\"type\":\"struct\",\"fields\":[]},\"nullable\":true,\"metadata\":{}},{\"name\":\"lc_secrets\",\"type\":{\"type\":\"struct\",\"fields\":[]},\"nullable\":true,\"metadata\":{}},{\"name\":\"metadata\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"language\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"page_content\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"type\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "latency",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "token_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "toxicity/v1/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "relevance/v1/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "relevance/v1/justification",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(result_llama.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b4ec76-1368-45bb-91ab-e991aafa19e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5af6fb8d40b4382bf974e0fccfde492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>questions</th><th>outputs</th><th>source_documents</th><th>latency</th><th>token_count</th><th>toxicity/v1/score</th><th>relevance/v1/score</th><th>relevance/v1/justification</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>\n",
       "MLflow is an open-source platform designed to help machine learning practitioners and teams manage the complexities of the machine learning process. It focuses on the full lifecycle of machine learning projects, ensuring that each phase is manageable, traceable, and reproducible.</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/index.html, MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation), MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n",
       "2.11.1\n",
       " MLflow\n",
       "What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "R API\n",
       "Java API\n",
       "REST API\n",
       "Official MLflow Docker Image\n",
       "Community Model Flavors\n",
       "Tutorials and Examples\n",
       "Contribute\n",
       "Documentation \n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle\n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle \n",
       "MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\n",
       "handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\n",
       "machine learning projects, ensuring that each phase is manageable, traceable, and reproducible., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/index.html, MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation), MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n",
       "2.11.1\n",
       " MLflow\n",
       "What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "R API\n",
       "Java API\n",
       "REST API\n",
       "Official MLflow Docker Image\n",
       "Community Model Flavors\n",
       "Tutorials and Examples\n",
       "Contribute\n",
       "Documentation \n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle\n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle \n",
       "MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\n",
       "handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\n",
       "machine learning projects, ensuring that each phase is manageable, traceable, and reproducible., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/index.html, MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation), MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n",
       "2.11.1\n",
       " MLflow\n",
       "What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "R API\n",
       "Java API\n",
       "REST API\n",
       "Official MLflow Docker Image\n",
       "Community Model Flavors\n",
       "Tutorials and Examples\n",
       "Contribute\n",
       "Documentation \n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle\n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle \n",
       "MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\n",
       "handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\n",
       "machine learning projects, ensuring that each phase is manageable, traceable, and reproducible., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/index.html, MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation), MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n",
       "2.11.1\n",
       " MLflow\n",
       "What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "R API\n",
       "Java API\n",
       "REST API\n",
       "Official MLflow Docker Image\n",
       "Community Model Flavors\n",
       "Tutorials and Examples\n",
       "Contribute\n",
       "Documentation \n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle\n",
       "MLflow: A Tool for Managing the Machine Learning Lifecycle \n",
       "MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\n",
       "handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\n",
       "machine learning projects, ensuring that each phase is manageable, traceable, and reproducible., Document))</td><td>1.4811196327</td><td>50</td><td>1.449935E-4</td><td>5</td><td>The output provides a comprehensive answer to the question, directly addressing what MLflow is and its focus on managing the machine learning lifecycle. The provided context is used effectively to answer the question thoroughly.</td></tr><tr><td>What is Databricks?</td><td>\n",
       "Databricks is a cloud-based big data platform that provides a unified analytics workspace for data engineering, data science, and machine learning tasks. It offers a collaborative environment for data teams to work together on data processing, analysis, and visualization tasks. Databricks is built on top of Apache Spark and provides additional tools and services to make it easier to use Spark for big data processing.\n",
       "\n",
       "The Databricks Community Edition (CE) is a free, limited-use version of Databricks that allows users to access a micro-cluster, a cluster manager, and a notebook environment. It also allows users to store and view their MLflow experiments without being charged. To use Databricks CE to store and view MLflow experiments, users need to create a free Databricks CE account, set up Databricks CE authentication in their dev environment, and connect to Databricks CE in their MLflow experiment session. The experiment results will then be automatically sent to Databricks CE, where they can be viewed in the MLflow experiment UI.</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks Community Edition (CE) is the free, limited-use version of the\n",
       "cloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\n",
       "a cluster manager and notebook environment. All users can share their notebooks and host them free of\n",
       "charge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\n",
       "being charged.\n",
       "To use Databricks CE to store and view our MLflow experiments, basically we need to:\n",
       "Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "Install Dependencies, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks Community Edition (CE) is the free, limited-use version of the\n",
       "cloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\n",
       "a cluster manager and notebook environment. All users can share their notebooks and host them free of\n",
       "charge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\n",
       "being charged.\n",
       "To use Databricks CE to store and view our MLflow experiments, basically we need to:\n",
       "Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "Install Dependencies, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks Community Edition (CE) is the free, limited-use version of the\n",
       "cloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\n",
       "a cluster manager and notebook environment. All users can share their notebooks and host them free of\n",
       "charge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\n",
       "being charged.\n",
       "To use Databricks CE to store and view our MLflow experiments, basically we need to:\n",
       "Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "Install Dependencies, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks Community Edition (CE) is the free, limited-use version of the\n",
       "cloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\n",
       "a cluster manager and notebook environment. All users can share their notebooks and host them free of\n",
       "charge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\n",
       "being charged.\n",
       "To use Databricks CE to store and view our MLflow experiments, basically we need to:\n",
       "Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "Install Dependencies, Document))</td><td>6.2711472511</td><td>210</td><td>3.271396E-4</td><td>5</td><td>The output provides a comprehensive answer to the input question, directly addressing Databricks Community Edition, its features, and how it can be used to store and view MLflow experiments. The provided context is directly utilized in the output, demonstrating a high level of relevance.</td></tr><tr><td>How to serve a model on Databricks?</td><td>\n",
       "To serve a model on Databricks, you need to follow these steps:\n",
       "\n",
       "1. Use MLflow to log your model into the Databricks MLflow server when you're using Databricks.\n",
       "2. Register your model after it has been logged.\n",
       "3. Serve your model by a few clicks on the production Databricks workspace.\n",
       "\n",
       "Please note that the serving feature is only available on the production Databricks workspace and not available on Databricks CE. The method of using production Databricks is the same as using Databricks CE, you only need to change the host to be the production workspace.\n",
       "\n",
       "For more information about how Databricks powers your Machine Learning workflow, please refer to the doc [here](https://docs.databricks.com/applications/mlflow/migration-guide.html).\n",
       "\n",
       "If you are using AzureML as the tracking server, please refer to the specific documentation for instructions on how to serve a model.</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\n",
       "MLflow server, and you can register your model then serve your model by a few clicks. Serving feature\n",
       "is only available on production Databricks workspace, and not available on Databricks CE.\n",
       "The method of using production Databricks is the same as using Databricks CE, you only need to\n",
       "change the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\n",
       "For more information about how Databricks power your Machine Learning workflow, please refer to the doc\n",
       "here.\n",
       "To use AzureML as the tracking server, please read\n",
       "the doc here\n",
       "Conclusion \n",
       "That’s all about how to use a production platform as the tracking server. Please see the pros and cons\n",
       "of this method below:\n",
       "Pros\n",
       "Effortless setup.\n",
       "Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\n",
       "MLflow server, and you can register your model then serve your model by a few clicks. Serving feature\n",
       "is only available on production Databricks workspace, and not available on Databricks CE.\n",
       "The method of using production Databricks is the same as using Databricks CE, you only need to\n",
       "change the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\n",
       "For more information about how Databricks power your Machine Learning workflow, please refer to the doc\n",
       "here.\n",
       "To use AzureML as the tracking server, please read\n",
       "the doc here\n",
       "Conclusion \n",
       "That’s all about how to use a production platform as the tracking server. Please see the pros and cons\n",
       "of this method below:\n",
       "Pros\n",
       "Effortless setup.\n",
       "Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\n",
       "MLflow server, and you can register your model then serve your model by a few clicks. Serving feature\n",
       "is only available on production Databricks workspace, and not available on Databricks CE.\n",
       "The method of using production Databricks is the same as using Databricks CE, you only need to\n",
       "change the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\n",
       "For more information about how Databricks power your Machine Learning workflow, please refer to the doc\n",
       "here.\n",
       "To use AzureML as the tracking server, please read\n",
       "the doc here\n",
       "Conclusion \n",
       "That’s all about how to use a production platform as the tracking server. Please see the pros and cons\n",
       "of this method below:\n",
       "Pros\n",
       "Effortless setup.\n",
       "Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.11.1 documentation), Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\n",
       "MLflow server, and you can register your model then serve your model by a few clicks. Serving feature\n",
       "is only available on production Databricks workspace, and not available on Databricks CE.\n",
       "The method of using production Databricks is the same as using Databricks CE, you only need to\n",
       "change the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\n",
       "For more information about how Databricks power your Machine Learning workflow, please refer to the doc\n",
       "here.\n",
       "To use AzureML as the tracking server, please read\n",
       "the doc here\n",
       "Conclusion \n",
       "That’s all about how to use a production platform as the tracking server. Please see the pros and cons\n",
       "of this method below:\n",
       "Pros\n",
       "Effortless setup.\n",
       "Good for collaboration, e.g., you can share your MLflow experiment with your teammates easily., Document))</td><td>4.9960212708</td><td>189</td><td>0.0014276962</td><td>5</td><td>The output directly answers the question about serving a model on Databricks by providing a clear and concise step-by-step guide. It is fully consistent with the provided context, which includes information about using production platforms as tracking servers and the specific steps for serving a model on Databricks. The output goes beyond simply mentioning the relationship between MLflow and Databricks, and instead provides a comprehensive answer to the user's question.</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>\n",
       "To enable MLflow autologging for your workspace by default, you can use the `mlflow.autolog()` function which enables autologging for each supported library you have installed as soon as you import it.\n",
       "\n",
       "Here's an example of how to use it:\n",
       "```python\n",
       "import mlflow\n",
       "mlflow.autolog()\n",
       "```\n",
       "However, if you want to enable autologging only for specific libraries, you can use the flavored versions of `autolog()` function for those libraries. For example, to enable autologging only for PyTorch, you can use:\n",
       "```python\n",
       "import mlflow\n",
       "mlflow.pytorch.autolog()\n",
       "```\n",
       "And to disable autologging for scikit-learn, you can use:\n",
       "```python\n",
       "import mlflow\n",
       "mlflow.sklearn.autolog(disable=True)\n",
       "```\n",
       "This way, you can enable autologging for the libraries you want and disable it for the ones you don't need.\n",
       "\n",
       "Note that the `extra_tags` parameter you see in the examples is optional and can be used to add extra tags to the logged metrics and artifacts.</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation), extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow\n",
       "# Option 1: Enable autologging only for PyTorch\n",
       "mlflow.pytorch.autolog()\n",
       "# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\n",
       "mlflow.sklearn.autolog(disable=True)\n",
       "mlflow.autolog()\n",
       "Supported Libraries \n",
       "Note\n",
       "The generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation), extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow\n",
       "# Option 1: Enable autologging only for PyTorch\n",
       "mlflow.pytorch.autolog()\n",
       "# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\n",
       "mlflow.sklearn.autolog(disable=True)\n",
       "mlflow.autolog()\n",
       "Supported Libraries \n",
       "Note\n",
       "The generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation), extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow\n",
       "# Option 1: Enable autologging only for PyTorch\n",
       "mlflow.pytorch.autolog()\n",
       "# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\n",
       "mlflow.sklearn.autolog(disable=True)\n",
       "mlflow.autolog()\n",
       "Supported Libraries \n",
       "Note\n",
       "The generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it., Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation), extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow\n",
       "# Option 1: Enable autologging only for PyTorch\n",
       "mlflow.pytorch.autolog()\n",
       "# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\n",
       "mlflow.sklearn.autolog(disable=True)\n",
       "mlflow.autolog()\n",
       "Supported Libraries \n",
       "Note\n",
       "The generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it., Document))</td><td>5.330129385</td><td>223</td><td>0.001882065</td><td>5</td><td>The output directly answers the user's question about enabling MLflow autologging for their workspace by default, providing a clear and concise explanation along with examples for specific libraries. The provided context is utilized effectively, making the answer comprehensive and fully relevant to the input.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         "\nMLflow is an open-source platform designed to help machine learning practitioners and teams manage the complexities of the machine learning process. It focuses on the full lifecycle of machine learning projects, ensuring that each phase is manageable, traceable, and reproducible.",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/index.html",
            "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation"
           ],
           "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n2.11.1\n MLflow\nWhat is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nR API\nJava API\nREST API\nOfficial MLflow Docker Image\nCommunity Model Flavors\nTutorials and Examples\nContribute\nDocumentation \nMLflow: A Tool for Managing the Machine Learning Lifecycle\nMLflow: A Tool for Managing the Machine Learning Lifecycle \nMLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\nhandling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\nmachine learning projects, ensuring that each phase is manageable, traceable, and reproducible.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/index.html",
            "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation"
           ],
           "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n2.11.1\n MLflow\nWhat is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nR API\nJava API\nREST API\nOfficial MLflow Docker Image\nCommunity Model Flavors\nTutorials and Examples\nContribute\nDocumentation \nMLflow: A Tool for Managing the Machine Learning Lifecycle\nMLflow: A Tool for Managing the Machine Learning Lifecycle \nMLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\nhandling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\nmachine learning projects, ensuring that each phase is manageable, traceable, and reproducible.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/index.html",
            "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation"
           ],
           "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n2.11.1\n MLflow\nWhat is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nR API\nJava API\nREST API\nOfficial MLflow Docker Image\nCommunity Model Flavors\nTutorials and Examples\nContribute\nDocumentation \nMLflow: A Tool for Managing the Machine Learning Lifecycle\nMLflow: A Tool for Managing the Machine Learning Lifecycle \nMLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\nhandling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\nmachine learning projects, ensuring that each phase is manageable, traceable, and reproducible.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/index.html",
            "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation"
           ],
           "MLflow: A Tool for Managing the Machine Learning Lifecycle — MLflow 2.11.1 documentation\n2.11.1\n MLflow\nWhat is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nR API\nJava API\nREST API\nOfficial MLflow Docker Image\nCommunity Model Flavors\nTutorials and Examples\nContribute\nDocumentation \nMLflow: A Tool for Managing the Machine Learning Lifecycle\nMLflow: A Tool for Managing the Machine Learning Lifecycle \nMLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in\nhandling the complexities of the machine learning process. MLflow focuses on the full lifecycle for\nmachine learning projects, ensuring that each phase is manageable, traceable, and reproducible.",
           "Document"
          ]
         ],
         1.4811196327,
         50,
         1.449935E-4,
         5,
         "The output provides a comprehensive answer to the question, directly addressing what MLflow is and its focus on managing the machine learning lifecycle. The provided context is used effectively to answer the question thoroughly."
        ],
        [
         "What is Databricks?",
         "\nDatabricks is a cloud-based big data platform that provides a unified analytics workspace for data engineering, data science, and machine learning tasks. It offers a collaborative environment for data teams to work together on data processing, analysis, and visualization tasks. Databricks is built on top of Apache Spark and provides additional tools and services to make it easier to use Spark for big data processing.\n\nThe Databricks Community Edition (CE) is a free, limited-use version of Databricks that allows users to access a micro-cluster, a cluster manager, and a notebook environment. It also allows users to store and view their MLflow experiments without being charged. To use Databricks CE to store and view MLflow experiments, users need to create a free Databricks CE account, set up Databricks CE authentication in their dev environment, and connect to Databricks CE in their MLflow experiment session. The experiment results will then be automatically sent to Databricks CE, where they can be viewed in the MLflow experiment UI.",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks Community Edition (CE) is the free, limited-use version of the\ncloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\na cluster manager and notebook environment. All users can share their notebooks and host them free of\ncharge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\nbeing charged.\nTo use Databricks CE to store and view our MLflow experiments, basically we need to:\nCreate a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\nInstall Dependencies",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks Community Edition (CE) is the free, limited-use version of the\ncloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\na cluster manager and notebook environment. All users can share their notebooks and host them free of\ncharge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\nbeing charged.\nTo use Databricks CE to store and view our MLflow experiments, basically we need to:\nCreate a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\nInstall Dependencies",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks Community Edition (CE) is the free, limited-use version of the\ncloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\na cluster manager and notebook environment. All users can share their notebooks and host them free of\ncharge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\nbeing charged.\nTo use Databricks CE to store and view our MLflow experiments, basically we need to:\nCreate a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\nInstall Dependencies",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks Community Edition (CE) is the free, limited-use version of the\ncloud-based big data platform Databricks. Databricks CE users can access a micro-cluster as well as\na cluster manager and notebook environment. All users can share their notebooks and host them free of\ncharge with Databricks. You can use Databricks CE to store and view your MLflow experiments without\nbeing charged.\nTo use Databricks CE to store and view our MLflow experiments, basically we need to:\nCreate a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\nInstall Dependencies",
           "Document"
          ]
         ],
         6.2711472511,
         210,
         3.271396E-4,
         5,
         "The output provides a comprehensive answer to the input question, directly addressing Databricks Community Edition, its features, and how it can be used to store and view MLflow experiments. The provided context is directly utilized in the output, demonstrating a high level of relevance."
        ],
        [
         "How to serve a model on Databricks?",
         "\nTo serve a model on Databricks, you need to follow these steps:\n\n1. Use MLflow to log your model into the Databricks MLflow server when you're using Databricks.\n2. Register your model after it has been logged.\n3. Serve your model by a few clicks on the production Databricks workspace.\n\nPlease note that the serving feature is only available on the production Databricks workspace and not available on Databricks CE. The method of using production Databricks is the same as using Databricks CE, you only need to change the host to be the production workspace.\n\nFor more information about how Databricks powers your Machine Learning workflow, please refer to the doc [here](https://docs.databricks.com/applications/mlflow/migration-guide.html).\n\nIf you are using AzureML as the tracking server, please refer to the specific documentation for instructions on how to serve a model.",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\nMLflow server, and you can register your model then serve your model by a few clicks. Serving feature\nis only available on production Databricks workspace, and not available on Databricks CE.\nThe method of using production Databricks is the same as using Databricks CE, you only need to\nchange the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\nFor more information about how Databricks power your Machine Learning workflow, please refer to the doc\nhere.\nTo use AzureML as the tracking server, please read\nthe doc here\nConclusion \nThat’s all about how to use a production platform as the tracking server. Please see the pros and cons\nof this method below:\nPros\nEffortless setup.\nGood for collaboration, e.g., you can share your MLflow experiment with your teammates easily.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\nMLflow server, and you can register your model then serve your model by a few clicks. Serving feature\nis only available on production Databricks workspace, and not available on Databricks CE.\nThe method of using production Databricks is the same as using Databricks CE, you only need to\nchange the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\nFor more information about how Databricks power your Machine Learning workflow, please refer to the doc\nhere.\nTo use AzureML as the tracking server, please read\nthe doc here\nConclusion \nThat’s all about how to use a production platform as the tracking server. Please see the pros and cons\nof this method below:\nPros\nEffortless setup.\nGood for collaboration, e.g., you can share your MLflow experiment with your teammates easily.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\nMLflow server, and you can register your model then serve your model by a few clicks. Serving feature\nis only available on production Databricks workspace, and not available on Databricks CE.\nThe method of using production Databricks is the same as using Databricks CE, you only need to\nchange the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\nFor more information about how Databricks power your Machine Learning workflow, please refer to the doc\nhere.\nTo use AzureML as the tracking server, please read\nthe doc here\nConclusion \nThat’s all about how to use a production platform as the tracking server. Please see the pros and cons\nof this method below:\nPros\nEffortless setup.\nGood for collaboration, e.g., you can share your MLflow experiment with your teammates easily.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.11.1 documentation"
           ],
           "Databricks or Microsoft AzureML. If you use Databricks, MLflow experiment will log your model into the Databricks\nMLflow server, and you can register your model then serve your model by a few clicks. Serving feature\nis only available on production Databricks workspace, and not available on Databricks CE.\nThe method of using production Databricks is the same as using Databricks CE, you only need to\nchange the host to be the production workspace. For example, https://dbc-1234567-123.cloud.databricks.com.\nFor more information about how Databricks power your Machine Learning workflow, please refer to the doc\nhere.\nTo use AzureML as the tracking server, please read\nthe doc here\nConclusion \nThat’s all about how to use a production platform as the tracking server. Please see the pros and cons\nof this method below:\nPros\nEffortless setup.\nGood for collaboration, e.g., you can share your MLflow experiment with your teammates easily.",
           "Document"
          ]
         ],
         4.9960212708,
         189,
         0.0014276962,
         5,
         "The output directly answers the question about serving a model on Databricks by providing a clear and concise step-by-step guide. It is fully consistent with the provided context, which includes information about using production platforms as tracking servers and the specific steps for serving a model on Databricks. The output goes beyond simply mentioning the relationship between MLflow and Databricks, and instead provides a comprehensive answer to the user's question."
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         "\nTo enable MLflow autologging for your workspace by default, you can use the `mlflow.autolog()` function which enables autologging for each supported library you have installed as soon as you import it.\n\nHere's an example of how to use it:\n```python\nimport mlflow\nmlflow.autolog()\n```\nHowever, if you want to enable autologging only for specific libraries, you can use the flavored versions of `autolog()` function for those libraries. For example, to enable autologging only for PyTorch, you can use:\n```python\nimport mlflow\nmlflow.pytorch.autolog()\n```\nAnd to disable autologging for scikit-learn, you can use:\n```python\nimport mlflow\nmlflow.sklearn.autolog(disable=True)\n```\nThis way, you can enable autologging for the libraries you want and disable it for the ones you don't need.\n\nNote that the `extra_tags` parameter you see in the examples is optional and can be used to add extra tags to the logged metrics and artifacts.",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation"
           ],
           "extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\nSee mlflow.autolog() for the full set of arguments you can use.\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow\n# Option 1: Enable autologging only for PyTorch\nmlflow.pytorch.autolog()\n# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\nmlflow.sklearn.autolog(disable=True)\nmlflow.autolog()\nSupported Libraries \nNote\nThe generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation"
           ],
           "extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\nSee mlflow.autolog() for the full set of arguments you can use.\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow\n# Option 1: Enable autologging only for PyTorch\nmlflow.pytorch.autolog()\n# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\nmlflow.sklearn.autolog(disable=True)\nmlflow.autolog()\nSupported Libraries \nNote\nThe generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation"
           ],
           "extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\nSee mlflow.autolog() for the full set of arguments you can use.\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow\n# Option 1: Enable autologging only for PyTorch\nmlflow.pytorch.autolog()\n# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\nmlflow.sklearn.autolog(disable=True)\nmlflow.autolog()\nSupported Libraries \nNote\nThe generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it.",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.11.1 documentation"
           ],
           "extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\nSee mlflow.autolog() for the full set of arguments you can use.\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow\n# Option 1: Enable autologging only for PyTorch\nmlflow.pytorch.autolog()\n# Option 2: Disable autologging for scikit-learn, but enable it for other libraries\nmlflow.sklearn.autolog(disable=True)\nmlflow.autolog()\nSupported Libraries \nNote\nThe generic autolog function mlflow.autolog() enables autologging for each supported library you have installed as soon as you import it.",
           "Document"
          ]
         ],
         5.330129385,
         223,
         0.001882065,
         5,
         "The output directly answers the user's question about enabling MLflow autologging for their workspace by default, providing a clear and concise explanation along with examples for specific libraries. The provided context is utilized effectively, making the answer comprehensive and fully relevant to the input."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "questions",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source_documents",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"lc_attributes\",\"type\":{\"type\":\"struct\",\"fields\":[]},\"nullable\":true,\"metadata\":{}},{\"name\":\"lc_secrets\",\"type\":{\"type\":\"struct\",\"fields\":[]},\"nullable\":true,\"metadata\":{}},{\"name\":\"metadata\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"language\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"page_content\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"type\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "latency",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "token_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "toxicity/v1/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "relevance/v1/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "relevance/v1/justification",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(result_mixtral.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8943b305-8837-4d8c-9efa-60c7526a01f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "demo_rag_evaluation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
